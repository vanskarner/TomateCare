package com.vanskarner.analysistracking.computervision

import android.content.Context
import android.graphics.Bitmap
import com.vanskarner.analysistracking.Predictions
import com.vanskarner.analysistracking.ml.TomatoDiseaseMobilenetv2
import org.tensorflow.lite.DataType
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.support.tensorbuffer.TensorBuffer
import org.tensorflow.lite.support.tensorbuffer.TensorBufferFloat
import java.io.FileInputStream
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel

fun useMobilenetV2WithAutogeneratedModel(context: Context, imgBitmap: Bitmap): Result<Predictions> {
    try {
        val model = TomatoDiseaseMobilenetv2.newInstance(context)
        val shape = intArrayOf(
            1,//batch size is equal to the number of images to be predicted
            CLASSIFICATION_IMG_SIZE,
            CLASSIFICATION_IMG_SIZE,
            CLASSIFICATION_CHANNELS
        )
        val inputFeature0 = TensorBuffer.createFixedSize(shape, DataType.FLOAT32)
        val imgByteBuffer = bitmapToByteBuffer(imgBitmap)
        inputFeature0.loadBuffer(imgByteBuffer)
        val outputTensor = model.process(inputFeature0).outputFeature0AsTensorBuffer
        model.close()
        val predictionsWithSoftmax = softmax(outputTensor.floatArray)
        val labeledPredictions = pairsLabelPrediction(predictionsWithSoftmax)
        val topPrediction = getTopPrediction(labeledPredictions)
        return if (topPrediction.first == CLASSIFICATION_CLASSES[2])
            Result.success(Predictions.healthy(topPrediction.second, labeledPredictions))
        else Result.success(Predictions.sick(topPrediction, labeledPredictions))
    } catch (exception: Exception) {
        return Result.failure(exception)
    }
}

fun useMobilenetV2WithInterpreter(context: Context, imgBitmap: Bitmap): Result<Predictions> {
    try {
        val interpreter = Interpreter(loadModelFile(context))
        val shape =
            intArrayOf(
                1,//batch size is equal to the number of images to be predicted
                CLASSIFICATION_IMG_SIZE,
                CLASSIFICATION_IMG_SIZE,
                CLASSIFICATION_CHANNELS
            )
        val inputTensor = TensorBufferFloat.createFixedSize(shape, DataType.FLOAT32)
        inputTensor.loadBuffer(bitmapToByteBuffer(imgBitmap))
        val outputShape = intArrayOf(1, 10)
        val outputTensor = TensorBufferFloat.createFixedSize(outputShape, DataType.FLOAT32)
        interpreter.run(inputTensor.buffer, outputTensor.buffer)
        interpreter.close()
        val softmaxPredictions = softmax(outputTensor.floatArray)
        val labeledPredictions = pairsLabelPrediction(softmaxPredictions)
        val topPrediction = getTopPrediction(labeledPredictions)
        return if (topPrediction.first == CLASSIFICATION_CLASSES[2])
            Result.success(Predictions.healthy(topPrediction.second, labeledPredictions))
        else Result.success(Predictions.sick(topPrediction, labeledPredictions))
    } catch (exception: Exception) {
        return Result.failure(exception)
    }
}

fun useMobilenetV2WithInterpreter(context: Context, imgList: List<Bitmap>): List<Predictions> {
    val interpreter = Interpreter(loadModelFile(context))
    val batchSize = imgList.size
    val shape = intArrayOf(
        batchSize,//batch size is equal to the number of images to be predicted
        CLASSIFICATION_IMG_SIZE,
        CLASSIFICATION_IMG_SIZE,
        CLASSIFICATION_CHANNELS
    )
    val inputTensor = TensorBufferFloat.createFixedSize(shape, DataType.FLOAT32)
    interpreter.resizeInput(0, shape)
    interpreter.allocateTensors()
    inputTensor.loadBuffer(bitmapListToByteBuffer(imgList))
    val outputShape = intArrayOf(batchSize, CLASSIFICATION_NUM_CLASSES)
    val outputTensor = TensorBufferFloat.createFixedSize(outputShape, DataType.FLOAT32)
    interpreter.run(inputTensor.buffer, outputTensor.buffer)
    interpreter.close()
    val predictions = mutableListOf<Predictions>()
    outputTensor.floatArray.toList().chunked(10).forEach {
        val softmaxPredictions = softmax(it.toFloatArray())
        val labeledPredictions = pairsLabelPrediction(softmaxPredictions)
        val topPrediction = getTopPrediction(labeledPredictions)
        if (topPrediction.first == CLASSIFICATION_CLASSES[2])
            predictions.add(Predictions.healthy(topPrediction.second, labeledPredictions))
        else predictions.add(Predictions.sick(topPrediction, labeledPredictions))
    }
    return predictions
}

private fun loadModelFile(context: Context): MappedByteBuffer {
    val modelPath = "Tomato_Disease-MobilenetV2.tflite"
    val fileInputStream = FileInputStream(context.assets.openFd(modelPath).fileDescriptor)
    val fileChannel = fileInputStream.channel
    val startOffset = context.assets.openFd(modelPath).startOffset
    val declaredLength = context.assets.openFd(modelPath).declaredLength
    return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
}